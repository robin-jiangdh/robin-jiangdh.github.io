<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title>Robin Log</title>
		<link>http://blog.robinjiang.com/</link>
		<description>Live In an awesome life!</description>
		<copyright>2020</copyright>
		<pubDate>Sat, 04 Apr 2020 10:08:06 GMT</pubDate>
		<lastBuildDate>Sat, 04 Apr 2020 10:08:06 GMT</lastBuildDate>
		<item>
			<title>carbon-一个能生成漂亮的代码截图工具</title>
			<link>http://blog.robinjiang.com/posts/2020/03/carbon-codetools</link>
			<guid>http://blog.robinjiang.com/posts/2020/03/carbon-codetools</guid>
			<pubDate>Tue, 24 Mar 2020 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>使用mailkit 和mimekit来发送邮件</title>
			<link>http://blog.robinjiang.com/posts/2019/10/2017-06-10-use-mailkit-with-mimekit-to-send-email</link>
			<description>&lt;p&gt;MailKit is a cross-platform mail client library built on top of &lt;a href="https://github.com/jstedfast/MimeKit"&gt;MimeKit&lt;/a&gt;.&lt;/p&gt;</description>
			<guid>http://blog.robinjiang.com/posts/2019/10/2017-06-10-use-mailkit-with-mimekit-to-send-email</guid>
			<pubDate>Thu, 24 Oct 2019 00:00:00 GMT</pubDate>
			<content:encoded>&lt;h2 id="mailkitmimekit"&gt;&lt;a href="https://github.com/jstedfast/MailKit"&gt;mailkit&lt;/a&gt;和&lt;a href="https://github.com/jstedfast/MimeKit"&gt;mimekit&lt;/a&gt; 是什么&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;h2 id="what-is-mailkit"&gt;What is MailKit?&lt;/h2&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;MailKit is a cross-platform mail client library built on top of &lt;a href="https://github.com/jstedfast/MimeKit"&gt;MimeKit&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;h2 id="what-is-mimekit"&gt;What is MimeKit?&lt;/h2&gt;
&lt;/blockquote&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;MimeKit is a C# library which may be used for the creation and parsing of messages using the Multipurpose Internet Mail Extension (MIME), as defined by &lt;a href="https://github.com/jstedfast/MimeKit/blob/master/RFCs.md"&gt;numerous IETF specifications&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="section"&gt;怎么用&lt;/h2&gt;
&lt;p&gt;分为发信和收信功能&lt;/p&gt;
&lt;h3 id="section-1"&gt;发信&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt; 
	var message = new MimeMessage ();
	message.From.Add (new MailboxAddress (&amp;quot;Joey Tribbiani&amp;quot;, &amp;quot;joey&amp;#64;friends.com&amp;quot;));
	message.To.Add (new MailboxAddress (&amp;quot;Mrs. Chanandler Bong&amp;quot;, &amp;quot;chandler&amp;#64;friends.com&amp;quot;));
	message.Subject = &amp;quot;How you doin'?&amp;quot;;
    message.Body = new TextPart (&amp;quot;plain&amp;quot;) {
				Text = &amp;#64;&amp;quot;Hey Chandler,
I just wanted to let you know that
Monica and I were going to go play some paintball, you in?
-- Joey&amp;quot;
			};

	using (var client = new SmtpClient ()) {
		// For demo-purposes, 
        //accept all SSL certificates (in case the server supports STARTTLS)
		client.ServerCertificateValidationCallback = (s,c,h,e) =&amp;gt; true;

		client.Connect (&amp;quot;smtp.friends.com&amp;quot;, 587, false);

		// Note: only needed if the SMTP server requires authentication
		client.Authenticate (&amp;quot;joey&amp;quot;, &amp;quot;password&amp;quot;);

		client.Send (message);
		client.Disconnect (true);
	}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="section-2"&gt;收信&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;using (var client = new Pop3Client ()) {
	// For demo-purposes, 
    //accept all SSL certificates (in case the server supports STARTTLS)
		client.ServerCertificateValidationCallback = (s,c,h,e) =&amp;gt; true;

		client.Connect (&amp;quot;pop.friends.com&amp;quot;, 110, false);

		client.Authenticate (&amp;quot;joey&amp;quot;, &amp;quot;password&amp;quot;);

		for (int i = 0; i &amp;lt; client.Count; i++) {
			var message = client.GetMessage (i);
			   Console.WriteLine (&amp;quot;Subject: {0}&amp;quot;, message.Subject);
			}
           client.Disconnect (true);
			}
&lt;/code&gt;&lt;/pre&gt;
</content:encoded>
		</item>
		<item>
			<title>SQL优化器原理——查询优化器综述</title>
			<link>http://blog.robinjiang.com/posts/2018/11/2018-08-23-sql-optimized-principles</link>
			<description>&lt;p&gt;摘要： 本文主要是对数据库查询优化器的一个综述，包括查询优化器分类、查询优化器执行过程和CBO框架Calcite。这是MaxCompute有关SQL优化器原理的系列文章之一。我们会陆续推出SQL优化器有关优化规则和框架的其他文章。&lt;/p&gt;</description>
			<guid>http://blog.robinjiang.com/posts/2018/11/2018-08-23-sql-optimized-principles</guid>
			<pubDate>Sat, 24 Nov 2018 00:00:00 GMT</pubDate>
			<content:encoded>&lt;blockquote class="blockquote"&gt;
&lt;p&gt;摘要： 本文主要是对数据库查询优化器的一个综述，包括查询优化器分类、查询优化器执行过程和CBO框架Calcite。这是MaxCompute有关SQL优化器原理的系列文章之一。我们会陆续推出SQL优化器有关优化规则和框架的其他文章。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文主要是对数据库查询优化器的一个综述，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查询优化器定义、分类&lt;/li&gt;
&lt;li&gt;查询优化器执行过程&lt;/li&gt;
&lt;li&gt;CBO框架Calcite简介&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="section"&gt;1.查询优化器是什么&lt;/h2&gt;
&lt;p&gt;数据库主要由三部分组成，分别是解析器、优化器和执行引擎，如下图所示：
&lt;img src="asset/img/sql.jpg" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;p&gt;其中优化器是数据库中用于把关系表达式转换成执行计划的核心组件，很大程度上决定了一个系统的性能。&lt;/p&gt;
&lt;h2 id="section-1"&gt;2.查询优化器分类&lt;/h2&gt;
&lt;p&gt;查询优化器分为两类：基于规则的优化器(Rule-Based Optimizer，RBO) 和基于代价的优化器(Cost-Based Optimizer，CBO) ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;基于规则的优化器(Rule-Based Optimizer，RBO)
根据优化规则对关系表达式进行转换，这里的转换是说一个关系表达式经过优化规则后会变成另外一个关系表达式，同时原有表达式会被裁剪掉，经过一系列转换后生成最终的执行计划。
RBO中包含了一套有着严格顺序的优化规则，同样一条SQL，无论读取的表中数据是怎么样的，最后生成的执行计划都是一样的。同时，在RBO中SQL写法的不同很有可能影响最终的执行计划，从而影响脚本性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;基于代价的优化器(Cost-Based Optimizer，CBO)
根据优化规则对关系表达式进行转换，这里的转换是说一个关系表达式经过优化规则后会生成另外一个关系表达式，同时原有表达式也会保留，经过一系列转换后会生成多个执行计划，然后CBO会根据统计信息和代价模型(Cost Model)计算每个执行计划的Cost，从中挑选Cost最小的执行计划。由上可知，CBO中有两个依赖：统计信息和代价模型。统计信息的准确与否、代价模型的合理与否都会影响CBO选择最优计划。
从上述描述可知，CBO是优于RBO的，原因是RBO是一种只认规则，对数据不敏感的呆板的优化器，而在实际过程中，数据往往是有变化的，通过RBO生成的执行计划很有可能不是最优的。
事实上目前各大数据库和大数据计算引擎都倾向于使用CBO，例如从Oracle 10g开始，Oracle已经彻底放弃RBO，转而使用CBO；而Hive在0.14版本中也引入了CBO。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="section-2"&gt;3.查询优化器执行过程&lt;/h2&gt;
&lt;p&gt;无论是RBO，还是CBO都包含了一系列优化规则，这些优化规则可以对关系表达式进行等价转换，常见的优化规则包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;谓词下推&lt;/li&gt;
&lt;li&gt;列裁剪&lt;/li&gt;
&lt;li&gt;常量折叠&lt;/li&gt;
&lt;li&gt;其他&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这些优化规则的基础上，就能对关系表达式做相应的等价转换，从而生成执行计划。下面将介绍RBO和CBO两种优化器的执行过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RBO&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RBO的执行过程比较简单，主要包含两个步骤：&lt;/p&gt;
&lt;p&gt;1）Transformation&lt;/p&gt;
&lt;p&gt;遍历关系表达式，只要模式能够满足特定优化规则就进行转换。&lt;/p&gt;
&lt;p&gt;2）Build Physical Plan&lt;/p&gt;
&lt;p&gt;经过Step1之后就生成了一个逻辑执行计划，但这只是逻辑上可行，还需要将逻辑执行计划build成物理执行计划，即决定各个Operator的具体实现。如Join算子的具体实现选择BroadcastHashJoin还是SortMergeJoin。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CBO&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CBO查询优化主要包含三个步骤：&lt;/p&gt;
&lt;p&gt;1）Exploration&lt;/p&gt;
&lt;p&gt;根据优化规则进行等价转换，生成等价关系表达式，此时原有关系表达式会被保留。&lt;/p&gt;
&lt;p&gt;2）Build Physical Plan&lt;/p&gt;
&lt;p&gt;决定各个Operator的具体实现。&lt;/p&gt;
&lt;p&gt;3）Find Best Plan&lt;/p&gt;
&lt;p&gt;根据统计信息计算各个执行计划的Cost，选择Cost最小的执行计划。
CBO实现有两种模型，即Volcano模型[1]和Cascades模型[2]，其中Calcite使用的是Volcano模型，而Orca[3]使用的是Cascades模型。这两种模型的思想基本相同，不同点在于Cascades模型并不是先Explore、后Build，而是边Explore边Build，从而进一步裁剪掉一些执行计划。在这里就不展开了，对此感兴趣的同学可以看下相关的论文。&lt;/p&gt;
&lt;h2 id="cbocalcite"&gt;4.CBO框架Calcite简介&lt;/h2&gt;
&lt;p&gt;Apache Calcite 是一个独立于存储与执行的SQL优化引擎，广泛应用于开源大数据计算引擎中，如Flink、Drill、Hive、Kylin等。另外，MaxCompute也使用了Calcite作为优化器框架。Calcite的架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src="asset/img/calcite.jpg" class="img-fluid" alt="" /&gt;&lt;/p&gt;
&lt;p&gt;其中Operator Expressions 指的是关系表达式，一个关系表达式在Calcite中被表示为RelNode，往往以根节点代表整个查询树。Calcite中有两种方法生成RelNode：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过Parser直接解析生成
从上述架构图可以看到，Calcite也提供了Parser用于SQL解析，直接使用Parser就能得到RelNode Tree。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;通过Expressions Builder转换生成
不同系统语法有差异，所以Parser也可能不同。针对这种情况，Calcite提供了Expressions Builder来对抽象语法树(或其他数据结构)进行转换得到RelNode Tree。如Hive(某一种Data Processing System)使用的就是这种方法。
Query Optimizer 根据优化规则(Pluggable Rules)对Operator Expressions进行一系列的等价转换，生成不同的执行计划，最后选择代价最小的执行计划，其中代价计算时会用到Metadata Providers提供的统计信息。
事实上，Calcite提供了RBO和CBO两种优化方式，分别对应HepPlanner和VolcanoPlanner。对此，本文也不进行展开，后续有时间再详细介绍Calcite的具体实现。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="section-3"&gt;5.总结&lt;/h2&gt;
&lt;p&gt;本文是对查询优化器的一个综述，介绍了查询优化器的分类、执行过程，以及优化器通用框架Calcite。&lt;/p&gt;
&lt;h2 id="section-4"&gt;6.参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[1] The Volcano Optimizer Generator: Extensibility and Efficient Search&lt;/li&gt;
&lt;li&gt;[2] The Cascades Framework for Query Optimization&lt;/li&gt;
&lt;li&gt;[3] Orca: A Modular Query Optimizer Architecture for Big Data&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
		</item>
		<item>
			<title>日志系统概述以及参考</title>
			<link>http://blog.robinjiang.com/posts/2018/04/LoggingSystem</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/LoggingSystem</guid>
			<pubDate>Thu, 26 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>基于elk实践日志采集的若干知识点</title>
			<link>http://blog.robinjiang.com/posts/2018/04/Elasticsearch-logstash-kibana</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/Elasticsearch-logstash-kibana</guid>
			<pubDate>Tue, 24 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>abp 入门二三事</title>
			<link>http://blog.robinjiang.com/posts/2018/04/ABP-Intro</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/ABP-Intro</guid>
			<pubDate>Tue, 24 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>轻量级日志分析工具</title>
			<link>http://blog.robinjiang.com/posts/2018/04/seq</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/seq</guid>
			<pubDate>Tue, 10 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>另外一个日志组件</title>
			<link>http://blog.robinjiang.com/posts/2018/04/Serilog</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/Serilog</guid>
			<pubDate>Tue, 10 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>elk的一个企业级替代品Splunk</title>
			<link>http://blog.robinjiang.com/posts/2018/04/Splunk</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/Splunk</guid>
			<pubDate>Tue, 10 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>GELF，别的世界的日志规范</title>
			<link>http://blog.robinjiang.com/posts/2018/04/GELF</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/GELF</guid>
			<pubDate>Tue, 10 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>基于Nlog的日志实践</title>
			<link>http://blog.robinjiang.com/posts/2018/04/NLog</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/NLog</guid>
			<pubDate>Fri, 06 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>日志抽象组件</title>
			<link>http://blog.robinjiang.com/posts/2018/04/liblog</link>
			<guid>http://blog.robinjiang.com/posts/2018/04/liblog</guid>
			<pubDate>Tue, 03 Apr 2018 00:00:00 GMT</pubDate>
		</item>
		<item>
			<title>关于Metrics，Tracing和Logging</title>
			<link>http://blog.robinjiang.com/posts/2017/04/2017-12-04-metrics-tracing-logging</link>
			<description>&lt;p&gt;这是一篇翻译文章&lt;/p&gt;</description>
			<guid>http://blog.robinjiang.com/posts/2017/04/2017-12-04-metrics-tracing-logging</guid>
			<pubDate>Wed, 12 Apr 2017 00:00:00 GMT</pubDate>
			<content:encoded>&lt;blockquote class="blockquote"&gt;
&lt;p&gt;这是一篇翻译文章&lt;/p&gt;
&lt;p&gt;Peter Bourgon 原作： &lt;a href="http://peter.bourgon.org/blog/2017/02/21/metrics-tracing-and-logging.html"&gt;Metrics, tracing, and logging&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，我很荣幸的参加了 2017 分布式追踪峰会(2017 Distributed Tracing Summit)， 并和来自 AWS/X-Ray,
OpenZipkin, OpenTracing, Instana, Datadog, Librato，以及其他更多组织的同仁进行了愉快的沟通和讨论。
其中一个重要的论点，是针对监控项目的范围和定义的。作为一个分布式追踪系统，应该管理日志么?从不同角度看来，到底什么是日志?如何通过一张图形象的定位这些形形色色的系统?&lt;/p&gt;
&lt;p&gt;总体说来，我觉得我们是在一些通用的名词间纠结。我想我们可以通过图表来定义监控的作用域，使各名词的作用范围更明确。 我们使用维恩图(Venn diagram)来描述 Metrics, Tracing, Logging 三个概念的定义。他们三者在某些情况下是重叠的，但是我尽量尝试定义他们的不同。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog.robinjiang.com/asset/2017-12-04-metrics-tracing-logging/01.png" class="img-fluid" alt="Annotated Venn diagram" /&gt;&lt;/p&gt;
&lt;p&gt;Metrics 的特点是，它是可累加的， 他们具有原子性，每个都是一个逻辑计量单元，或者一个时间段内的柱状图。&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;例如：队列的当前深度可以被定义为一个计量单元，在写入或读取时被更新统计; 输入 HTTP 请求的数量可以被定义为一个计数器，用于简单累加;请求的执行时间可以被定义为一个柱状图，在指定时间片上更新和统计汇总。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Logging 的特点是，它描述一些离散的(不连续的)事件。&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;例如：应用通过一个滚动的文件输出 Debug 或 Error 信息，并通过日志收集系统，存储到 Elasticsearch 中;
审批明细信息通过 Kafka，存储到数据库(BigTable)中;
又或者，特定请求的元数据信息，从服务请求中剥离出来，发送给一个异常收集服务，如 NewRelic。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tracing 的最大特点就是，它在单次请求的范围内，处理信息。 任何的数据、元数据信息都被绑定到系统中的单个事务上。&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;例如：一次调用远程服务的 RPC 执行过程;一次实际的 SQL 查询语句;一次 HTTP 请求的业务性 ID。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据上述的定义，我们可以标记上图的重叠部分。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog.robinjiang.com/asset/2017-12-04-metrics-tracing-logging/02.png" class="img-fluid" alt="修正的带注释的维恩图" /&gt;&lt;/p&gt;
&lt;p&gt;当然，大量的被监控的应用是具有分布式能力(Cloud-native)的应用，逻辑处理在单次请求的范围内完成。因此，讨论追踪的上下文是有意义的。但是，我们注意到，并不是所有的监控系统都绑定在请求的生命周期上的。他们可能是逻辑组件诊断信息、处理过程的生命周期明细信息，这些信息和任何离散的请求时正交关系。&lt;/p&gt;
&lt;p&gt;所以，不是所有的 Metrics 和 Log 都可以被塞进追踪系统的概念中，至少在不经过数据加工处理是不行的。又或者，我们可能发觉使用 Metrics 统计数据，对应用监控有很大帮助，例如 Prometheus 生态，可以量化的实时展现应用视图;相应的，如果我们将 Metrics 统计数据强行使用针对 Log 的管道来处理，将使我们丢失很多特性。&lt;/p&gt;
&lt;p&gt;那么，在这里，我们可以开始对已知的系统进行分类。如：Prometheus，专一的 Metrics 统计系统，随着时间推移，也许会进化为追踪系统，进而进行请求内的指标统计，但不太可能深入到 Log 处理领域。ELK 生态提供 Log 的记录，滚动和聚合，并在其他领域不停的积累更多的特性，并集成进来。&lt;/p&gt;
&lt;p&gt;另外，我发现通过维恩图的方式展现三者关系时，会正巧展现出一个附加效应。在这三个功能域中，Metrics 倾向于更节省资源，因为他会“天然的”压缩数据。相反，日志倾向于无限增加的，会频繁的超出预期的容量。(有另一篇我写的关于这方面的文章，查看，译者注：未翻译)。所以，我们可以在图上，绘制出容量的需求趋势，Metrics 低到 Logging 高，
而 Trace 可能处于他们两的中间位置&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog.robinjiang.com/asset/2017-12-04-metrics-tracing-logging/03.png" class="img-fluid" alt="带有梯度的维恩图" /&gt;&lt;/p&gt;
&lt;p&gt;也许，这不是最完美的方式描述这三者的管理，但我从会议现场收到的反馈来看，这个分类还是相当不错的：随着三者的关系越清晰，我们越容易建设性的讨论其他问题。如果你尝试对产品的功能进行定位，你可能也需要这张图。&lt;/p&gt;
</content:encoded>
		</item>
	</channel>
</rss>