<!DOCTYPE html SYSTEM "about:legacy-compat"><html lang="en-US" data-colors-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex">  <meta name="built-on" content="2023-12-17T23:19:47.9196465"><meta name="build-number" content="${buildNumber}">       <title>GROUP BY | blog</title><script id="virtual-toc-data" type="application/json">[{"id":"internal-implementation","level":0,"title":"Internal implementation","anchor":"#internal-implementation"},{"id":"two-level","level":0,"title":"Two-Level","anchor":"#two-level"},{"id":"group-by-in-external-memory","level":0,"title":"GROUP BY in external memory","anchor":"#group-by-in-external-memory"},{"id":"optimize-aggregation-in-order-group-by","level":0,"title":"optimize_aggregation_in_order GROUP BY","anchor":"#optimize-aggregation-in-order-group-by"},{"id":"last-item-cache","level":0,"title":"Last item cache","anchor":"#last-item-cache"},{"id":"stringhashmap","level":0,"title":"StringHashMap","anchor":"#stringhashmap"},{"id":"for-what-group-by-statement-use-memory","level":0,"title":"For what GROUP BY statement use memory","anchor":"#for-what-group-by-statement-use-memory"},{"id":"why-my-group-by-eat-all-the-ram","level":0,"title":"Why my GROUP BY eat all the RAM","anchor":"#why-my-group-by-eat-all-the-ram"}]</script><script id="topic-shortcuts" type="application/json"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.6.6-b205/app.css" rel="stylesheet">   <link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><link rel="manifest" href="https://jetbrains.com/site.webmanifest"><link rel="mask-icon" href="https://jetbrains.com/safari-pinned-tab.svg" color="#000000"><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"/><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"/><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"/><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"/><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"/>  <meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="GROUP BY | blog"/><meta property="og:description" content=""/><meta property="og:image" content=""/><meta property="og:site_name" content="blog Help"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_US"/><meta property="og:url" content="/blog/1.0/group-by-index.html"/><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="GROUP BY | blog"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json"> { "@context": "http://schema.org", "@type": "WebPage", "@id": "/blog/1.0/group-by-index.html#webpage", "url": "/blog/1.0/group-by-index.html", "name": "GROUP BY | blog", "description": "", "image": "", "inLanguage":"en-US" }</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json"> { "@type": "WebSite", "@id": "/blog/#website", "url": "/blog/", "name": "blog Help" }</script><!-- End Schema.org --></head>      <body data-id="group-by_index" data-main-title="GROUP BY" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}"  data-template="article"  data-breadcrumbs="Clickhouse///kb-queries-and-syntax///group-by"  >   <div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>blog 1.0 Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="group-by_index"   id="group-by_index.md">GROUP BY</h1>  <p id="e445d4a6_532">#GROUP BY linkTitle: &quot;GROUP BY&quot; keywords:</p><ul class="list _ul" id="e445d4a6_533"><li class="list__item" id="e445d4a6_534"><p>clickhouse queries</p></li><li class="list__item" id="e445d4a6_535"><p>clickhouse group by</p></li><li class="list__item" id="e445d4a6_536"><p>clickhouse memory description: &gt; Learn about GROUP BY clause in ClickHouse. weight: 1</p></li></ul><section class="chapter"><h2 id="internal-implementation" data-toc="internal-implementation"   >Internal implementation</h2><p id="e445d4a6_538"><a href="https://github.com/ClickHouse/ClickHouse/blob/8ab5270ded39c8b044f60f73c1de00c8117ab8f2/src/Interpreters/Aggregator.cpp#L382" id="e445d4a6_539"   data-external="true" rel="noopener noreferrer" >Code</a></p><p id="e445d4a6_540">ClickHouse uses non-blocking? hash tables, so each thread has at least one hash table.</p><p id="e445d4a6_541">It makes easier to not care about sync between multiple threads, but has such disadvantages as:</p><ol class="list _decimal" id="e445d4a6_542" type="1"><li class="list__item" id="e445d4a6_543"><p>Bigger memory usage.</p></li><li class="list__item" id="e445d4a6_544"><p>Needs to merge those per-thread hash tables afterwards.</p></li></ol><p id="e445d4a6_545">Because second step can be a bottleneck in case of a really big GROUP BY with a lot of distinct keys, another solution has been made.</p></section><section class="chapter"><h2 id="two-level" data-toc="two-level"   >Two-Level</h2><p id="e445d4a6_546">https://youtu.be/SrucFOs8Y6c?t=2132</p><div class="code-block" data-lang="none"         >
┌─name───────────────────────────────┬─value────┬─changed─┬─description────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─min──┬─max──┬─readonly─┬─type───┐
│ group_by_two_level_threshold       │ 100000   │       0 │ From what number of keys, a two-level aggregation starts. 0 - the threshold is not set.                                                                                                                    │ ᴺᵁᴸᴸ │ ᴺᵁᴸᴸ │        0 │ UInt64 │
│ group_by_two_level_threshold_bytes │ 50000000 │       0 │ From what size of the aggregation state in bytes, a two-level aggregation begins to be used. 0 - the threshold is not set. Two-level aggregation is used when at least one of the thresholds is triggered. │ ᴺᵁᴸᴸ │ ᴺᵁᴸᴸ │        0 │ UInt64 │
└────────────────────────────────────┴──────────┴─────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────┴──────┴──────────┴────────┘
</div><p id="e445d4a6_548">In order to parallelize merging of hash tables, ie execute such merge via multiple threads, ClickHouse use two-level approach:</p><p id="e445d4a6_549">On the first step ClickHouse creates 256 buckets for each thread. (determined by one byte of hash function) On the second step ClickHouse can merge those 256 buckets independently by multiple threads.</p><p id="e445d4a6_550">https://github.com/ClickHouse/ClickHouse/blob/1ea637d996715d2a047f8cd209b478e946bdbfb0/src/Common/HashTable/TwoLevelHashTable.h#L6</p></section><section class="chapter"><h2 id="group-by-in-external-memory" data-toc="group-by-in-external-memory"   >GROUP BY in external memory</h2><p id="e445d4a6_551">It utilizes a two-level group by and dumps those buckets on disk. And at the last stage ClickHouse will read those buckets from disk one by one and merge them. So you should have enough RAM to hold one bucket (1/256 of whole GROUP BY size).</p><p id="e445d4a6_552">https://clickhouse.com/docs/en/sql-reference/statements/select/group-by/#select-group-by-in-external-memory</p></section><section class="chapter"><h2 id="optimize-aggregation-in-order-group-by" data-toc="optimize-aggregation-in-order-group-by"   >optimize_aggregation_in_order GROUP BY</h2><p id="e445d4a6_553">Usually it works slower than regular GROUP BY, because ClickHouse need's to read and process data in specific ORDER, which makes it much more complicated to parallelize reading and aggregating.</p><p id="e445d4a6_554">But it use much less memory, because ClickHouse can stream resultset and there is no need to keep it in memory.</p></section><section class="chapter"><h2 id="last-item-cache" data-toc="last-item-cache"   >Last item cache</h2><p id="e445d4a6_555">ClickHouse saves value of previous hash calculation, just in case next value will be the same.</p><p id="e445d4a6_556">https://github.com/ClickHouse/ClickHouse/pull/5417 https://github.com/ClickHouse/ClickHouse/blob/808d9afd0f8110faba5ae027051bf0a64e506da3/src/Common/ColumnsHashingImpl.h#L40</p></section><section class="chapter"><h2 id="stringhashmap" data-toc="stringhashmap"   >StringHashMap</h2><p id="e445d4a6_557">Actually uses 5 different hash tables</p><ol class="list _decimal" id="e445d4a6_558" type="1"><li class="list__item" id="e445d4a6_559"><p>For empty strings</p></li><li class="list__item" id="e445d4a6_560"><p>For strings &lt; 8 bytes</p></li><li class="list__item" id="e445d4a6_561"><p>For strings &lt; 16 bytes</p></li><li class="list__item" id="e445d4a6_562"><p>For strings &lt; 24 bytes</p></li><li class="list__item" id="e445d4a6_563"><p>For strings &gt; 24 bytes</p></li></ol><div class="code-block" data-lang="none"         >
SELECT count()
FROM
(
    SELECT materialize('1234567890123456') AS key           -- length(key) = 16
    FROM numbers(1000000000)
)
GROUP BY key

Aggregator: Aggregation method: key_string

Elapsed: 8.888 sec. Processed 1.00 billion rows, 8.00 GB (112.51 million rows/s., 900.11 MB/s.)

SELECT count()
FROM
(
    SELECT materialize('12345678901234567') AS key          -- length(key) = 17
    FROM numbers(1000000000)
)
GROUP BY key

Aggregator: Aggregation method: key_string

Elapsed: 9.089 sec. Processed 1.00 billion rows, 8.00 GB (110.03 million rows/s., 880.22 MB/s.)

SELECT count()
FROM
(
    SELECT materialize('123456789012345678901234') AS key   -- length(key) = 24
    FROM numbers(1000000000)
)
GROUP BY key

Aggregator: Aggregation method: key_string

Elapsed: 9.134 sec. Processed 1.00 billion rows, 8.00 GB (109.49 million rows/s., 875.94 MB/s.)

SELECT count()
FROM
(
    SELECT materialize('1234567890123456789012345') AS key  -- length(key) = 25
    FROM numbers(1000000000)
)
GROUP BY key

Aggregator: Aggregation method: key_string

Elapsed: 12.566 sec. Processed 1.00 billion rows, 8.00 GB (79.58 million rows/s., 636.67 MB/s.)
</div><p id="e445d4a6_565">length</p><p id="e445d4a6_566">16 8.89 17 9.09 24 9.13 25 12.57</p></section><section class="chapter"><h2 id="for-what-group-by-statement-use-memory" data-toc="for-what-group-by-statement-use-memory"   >For what GROUP BY statement use memory</h2><ol class="list _decimal" id="e445d4a6_567" type="1"><li class="list__item" id="e445d4a6_568"><p>Hash tables</p></li></ol><p id="e445d4a6_569">It will grow with:</p><p id="e445d4a6_570">Amount of unique combinations of keys participated in GROUP BY</p><p id="e445d4a6_571">Size of keys participated in GROUP BY</p><ol class="list _decimal" id="e445d4a6_572" type="1" start="2"><li class="list__item" id="e445d4a6_573"><p>States of aggregation functions:</p></li></ol><p id="e445d4a6_574">Be careful with function, which state can use unrestricted amount of memory and grow indefenetely:</p><ul class="list _ul" id="e445d4a6_575"><li class="list__item" id="e445d4a6_576"><p>groupArray (groupArray(1000)())</p></li><li class="list__item" id="e445d4a6_577"><p>uniqExact (uniq,uniqCombined)</p></li><li class="list__item" id="e445d4a6_578"><p>quantileExact (medianExact) (quantile,quantileTDigest)</p></li><li class="list__item" id="e445d4a6_579"><p>windowFunnel</p></li><li class="list__item" id="e445d4a6_580"><p>groupBitmap</p></li><li class="list__item" id="e445d4a6_581"><p>sequenceCount (sequenceMatch)</p></li><li class="list__item" id="e445d4a6_582"><p>*Map</p></li></ul></section><section class="chapter"><h2 id="why-my-group-by-eat-all-the-ram" data-toc="why-my-group-by-eat-all-the-ram"   >Why my GROUP BY eat all the RAM</h2><ol class="list _decimal" id="e445d4a6_583" type="1"><li class="list__item" id="e445d4a6_584"><p id="e445d4a6_585">run your query with <code class="code" id="e445d4a6_586">set send_logs_level='trace'</code></p></li><li class="list__item" id="e445d4a6_587"><p id="e445d4a6_588">Remove all aggregation functions from the query, try to understand how many memory simple GROUP BY will take.</p></li><li class="list__item" id="e445d4a6_589"><p id="e445d4a6_590">One by one remove aggregation functions from query in order to understand which one is taking most of memory</p></li></ol></section><div class="last-modified"> Last modified: 17 十二月 2023</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom">  <a class="navigation-links__prev" href="tricks.html">GROUP BY tricks</a>   <a class="navigation-links__next" href="joins-index.html">JOINs</a>  </div></article><div id="disqus_thread"></div></div></section></main></div>  <script src="https://resources.jetbrains.com/writerside/apidoc/6.6.6-b205/app.js"></script></body></html>